# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fq81l1CYdTsSjrKdIFNCjSfbCm1xIZ8Q
"""

import pandas as pd
#from sklearn.metrics import plot_roc_curve
import scikitplot as skplt
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

data = pd.read_csv('Phone.csv')

df = pd.DataFrame(data)
df

df.isnull().sum()

df.info()

df.describe()

"""KNN"""

from sklearn.model_selection import train_test_split

from sklearn.neighbors import KNeighborsClassifier

from sklearn import metrics
from sklearn.metrics import confusion_matrix, auc, roc_curve
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay
from sklearn.metrics import ConfusionMatrixDisplay, classification_report
from statistics import stdev

from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# GridSearchCV
from sklearn.model_selection import GridSearchCV

#X and y Arrays
X = df.drop('price_range', axis = 1)
y = df['price_range'].values


# Check the shape of X and y
print ('x:', X.shape,'\ny:', y.shape)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

#Find the Best K for KNN Classifier
K = 31
accuracy = np.zeros ((K))

for i in range (2 , K+1):
    Knn = KNeighborsClassifier (n_neighbors = i)
    Knn.fit (X_train, y_train)
    y_pred = Knn.predict (X_test)
    accuracy [i-1] = metrics.accuracy_score (y_test, y_pred)
print (accuracy)
print(f'\nBest Accuracy is obtained {max(accuracy)}', "for K =", np.array(accuracy).argmax()+1)

#Find the Best Test Size
K = 7

# Array of test size value from 0.2 to 0.35
test_size = np.arange(start=0.2, stop=0.35, step= 0.05)

#Initialize a list where we'll store the score of each test size
score =[]
for size in test_size:
    X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=size, random_state=0)
    Knn = KNeighborsClassifier (n_neighbors = K)
    Knn.fit (X_train, y_train)
    score.append (Knn.score (X_test, y_test))

r= pd.DataFrame({'Test size': test_size , 'Score': score})
r.sort_values(by = ['Score'], ascending = False, inplace = True)
r.style.highlight_max(color='#acd9a8')

X_train, X_test, y_train, y_test = train_test_split (X, y, stratify=y, test_size = 0.25 , random_state = 0)

print('X_train shape: ', X_train.shape)
print('X_test shape: ', X_test.shape)
print('y_train shape: ', y_train.shape)
print('y_test shape: ',y_test.shape)

knn_model = KNeighborsClassifier(n_neighbors=19)
knn_model.fit(X_train, y_train)

y_pred = knn_model.predict(X_test)

print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

# print the scores on training and test set
print('Training set score: {:.4f}'.format(knn_model.score(X_train, y_train)))
print('Test set score: {:.4f}'.format(knn_model.score(X_test, y_test)))

#K-Fold Cross-validation
kf = KFold(n_splits=10, shuffle=False)

#Cross Validation Accuracy¶
score = cross_val_score(knn_model, X_train, y_train, cv=kf, scoring='accuracy')
knn_model_cv_score1 = score.mean()
knn_model_cv_stdev1 = stdev(score)
print('Cross Validation Accuracy scores are: {}'.format(score))

Accuracy  = ['Cross Validation Accuracy ']
knn_A = pd.DataFrame({'CV Mean':knn_model_cv_score1,'Std':knn_model_cv_stdev1},index=Accuracy )
knn_A

#Confusion Matrix
ConfusionMatrixDisplay.from_estimator(knn_model, X_test, y_test, colorbar=False, cmap='YlGnBu')
plt.title('Confusion Matrix of Base KNN')
plt.grid(False)

#Classification Report
print(classification_report(y_test, y_pred))

# Roc Curve for KNN


# fig, ax = plt.subplots(figsize=(6, 5), dpi=80)
# plot_roc_curve(knn_model, X_test, y_test, ax=ax)
# plt.title('ROC Curve - KNN')
# plt.show()

y_prob = knn_model.predict_proba(X_test)
skplt.metrics.plot_roc_curve(y_test, y_prob)
plt.title('منحنی ROC - KNN')
plt.show()


#Tune KNN Hyperparameters Using GridSearchCV
# Finding optimal hyperparameters(GridSearchCV)

# Define model
knn = KNeighborsClassifier()

# Define search parameters
k_range = list(range(2, 31))
weight_options = ['uniform', 'distance']
metric = ['euclidean', 'manhattan', 'minkowski']

param_grid = {"n_neighbors" : k_range , "weights" : weight_options , "metric" : metric}

# Define search
grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False, verbose=1, n_jobs=-1)

# Execute search
grid_search=grid.fit(X_train, y_train.ravel())

# Summarize result
print('Best Score: %s' % grid_search.best_score_)
print('Best Hyperparameters: %s' % grid_search.best_params_)

#Tuned Model
knn_modelcv = KNeighborsClassifier(metric= 'euclidean', n_neighbors= 4, weights= 'distance')
knn_modelcv.fit(X_train, y_train)

y_pred = knn_modelcv.predict(X_test)

print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

ConfusionMatrixDisplay.from_estimator(knn_modelcv, X_test, y_test, colorbar=False, cmap='YlGnBu')
plt.title('Confusion Matrix of Final KNN')
plt.grid(False)

print(classification_report(y_test, y_pred))

"""SVM"""

from sklearn.svm import SVC

Data = pd.read_csv('Phone.csv')

test = pd.read_csv('Phone.csv')

df = pd.DataFrame(Data)
df

df.describe()

#X and y Arrays

X = df.drop('price_range', axis=1)
# y = df['price_range'].values.reshape(-1, 1)
y = df['price_range'].values


print ('X:', X.shape,'\ny:', y.shape)

#Find the Best Test Size
# Array of test size value from 0.2 to 0.35
test_size = np.arange(start=0.2, stop=0.35, step=0.05)

# Initialize a list where we'll store the score of each test size
score = []
for size in test_size:
    X_train3, X_test3, y_train3, y_test3 = train_test_split (X, y, test_size=size, random_state=0)
    svm_model = SVC()
    svm_model.fit (X_train3, y_train3)
    score.append (svm_model.score (X_test3, y_test3))

# Create a dataframe to display the results
r= pd.DataFrame({'Test size': test_size, 'Score': score})
r.sort_values(by = ['Score'], ascending = False, inplace = True)
r.style.highlight_max(color='#acd9a8')

# Split X and y into training and testing sets
X_train3, X_test3, y_train3, y_test3 = train_test_split (X, y, stratify=y, test_size = 0.2 , random_state = 0)

# Check the shape of X_train, X_test, y_train and y_test
print('X_train shape:', X_train3.shape)
print('X_test shape:', X_test3.shape)
print('y_train shape:', y_train3.shape)
print('y_test shape:', y_test3.shape)

#Training SVM Model
# Instantiate the model
svm_model = SVC(probability=True)

# Fit the model to the training set
svm_model.fit(X_train3, y_train3)

#Predict X-test
y_pred = svm_model.predict(X_test3)

#Check Accuracy Score
print('Model Accuracy Score: {0:0.4f}'. format(accuracy_score(y_test3, y_pred)))

#Check for Overfitting and Underfitting
# Scores on training and test set
print('Training set score: {:.4f}'.format(svm_model.score(X_train3, y_train3)))
print('Test set score: {:.4f}'.format(svm_model.score(X_test3, y_test3)))

#K-Fold Cross-validation
kf = KFold(n_splits=10, shuffle=False)

#Cross Validation Accuracy
score = cross_val_score(svm_model, X_train3, y_train3, cv=kf, scoring='accuracy')
svm_model_cv_score = score.mean()
svm_model_cv_stdev = stdev(score)
print('Cross Validation Accuracy scores are:\n {}'.format(score))

Accuracy = ['Cross Validation Accuracy']
svm_A = pd.DataFrame({'CV Mean':svm_model_cv_score,'Std':svm_model_cv_stdev},index=Accuracy)
svm_A

#Confusion Matrix
ConfusionMatrixDisplay.from_estimator(svm_model, X_test3, y_test3, colorbar=False, cmap='YlGnBu')
plt.title('Confusion Matrix of Base SVM')
plt.grid(False)

#Classification Report
print(classification_report(y_test3, y_pred))

#Roc Curve
y_Pred_prob = svm_model.predict_proba(X_test3)

def roc_curve_plot(y_actual, y_predicted_probs, figsize=(5, 4), title=None, legend_loc='best'):

    # Compute ROC curve and ROC area for each class
    fpr = {}
    tpr = {}
    thres = {}
    roc_auc = {}

    n_class = y_predicted_probs.shape[1]
    for i in range(n_class):
        fpr[i], tpr[i], thres[i] = roc_curve(y_actual == i, y_predicted_probs[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Create a figure and plot the ROC curve for each class
    plt.figure(figsize=figsize)
    for i in range(n_class):
        plt.plot(fpr[i], tpr[i], linewidth=1, label='Class {}: AUC={:.2f}'.format(i, roc_auc[i]))

    # Add diagonal line and axis labels
    plt.plot([0, 1], [0, 1], '--', linewidth=0.5)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')

    # Set axis limits and add title and legend
    plt.xlim([0, 1])
    plt.ylim([0, 1.05])
    if title is not None:
        plt.title(title)
    plt.legend(loc=legend_loc)

    # Show the plot
    plt.show()

roc_curve_plot(y_test3, y_Pred_prob)

# Finding optimal hyperparameters(GridSearchCV)
from sklearn.model_selection import GridSearchCV

# Define model
model = SVC(probability=True)

# Define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)

# Define search parameters
C = [0.1, 1, 10, 100]
kernel = ['linear', 'poly', 'rbf', 'sigmoid']
gamma = ['scale', 'auto']

#degree = [2, 3, 4]
#coef0 = [0, 1, 2]

param_grid = {'C': C, 'kernel': kernel, 'gamma': gamma}

# Define search
search = GridSearchCV(model, param_grid, scoring='accuracy', n_jobs=-1, cv=cv)

# Execute search
GridSearchCV = search.fit(X_train3, y_train3)

# Set the clf to the best combination of parameters
svm_modelcv = GridSearchCV.best_estimator_

# Summarize result
print('Best Score: %s' % GridSearchCV.best_score_)
print('Best Hyperparameters: %s' % GridSearchCV.best_params_)

#Tuned Model
svm_modelcv = SVC(C = 10, gamma = 'scale', kernel = 'linear', probability=True)
svm_modelcv.fit(X_train3, y_train3)

y_pred = svm_modelcv.predict(X_test3)

print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test3, y_pred)))

ConfusionMatrixDisplay.from_estimator(svm_modelcv, X_test3, y_test3, colorbar=False, cmap='YlGnBu')
plt.title('Confusion Matrix of Tuned SVM')
plt.grid(False)

print(classification_report(y_test3, y_pred))

y_Pred_prob = svm_modelcv.predict_proba(X_test3)

def roc_curve_plot(y_actual, y_predicted_probs, figsize=(5, 4), title=None, legend_loc='best'):

    # Compute ROC curve and ROC area for each class
    fpr = {}
    tpr = {}
    thres = {}
    roc_auc = {}

    n_class = y_predicted_probs.shape[1]
    for i in range(n_class):
        fpr[i], tpr[i], thres[i] = roc_curve(y_actual == i, y_predicted_probs[:, i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Create a figure and plot the ROC curve for each class
    plt.figure(figsize=figsize)
    for i in range(n_class):
        plt.plot(fpr[i], tpr[i], linewidth=1, label='Class {}: AUC={:.2f}'.format(i, roc_auc[i]))

    # Add diagonal line and axis labels
    plt.plot([0, 1], [0, 1], '--', linewidth=0.5)
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')

    # Set axis limits and add title and legend
    plt.xlim([0, 1])
    plt.ylim([0, 1.05])
    if title is not None:
        plt.title(title)
    plt.legend(loc=legend_loc)

    # Show the plot
    plt.show()

roc_curve_plot(y_test3, y_Pred_prob)

print("------")